# backend/app/services/tutor_service.py

from langchain_community.llms import Ollama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from typing import List, Dict, Any 

from app.services.vector_store import get_retriever, OLLAMA_BASE_URL

# ì±„íŒ… ëª¨ë¸ ì •ì˜
OLLAMA_CHAT_MODEL = "gemma3:4b" 

# --- ì²´ì¸ êµ¬ì„± ---
try:
    print(f"Tutor Service: LLM ë¡œë“œ ì¤‘... ({OLLAMA_CHAT_MODEL})")
    llm = Ollama(model=OLLAMA_CHAT_MODEL, base_url=OLLAMA_BASE_URL)
    
    # (1) ë‹µë³€ ì²´ì¸ (ëŒ€í™” ëª¨ë“œìš©)
    # ì—­í• : ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ì¹œì ˆí•˜ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.
    template_answer = """
    [ì—­í• ] ì¹œì ˆí•œ AI íŠœí„° (ëŒ€í™” ëª¨ë“œ)
    [ì§€ì‹œ] ì§ˆë¬¸ì— ì¹œì ˆí•˜ê²Œ ë‹µí•˜ì„¸ìš”.
    [ì •ë³´] {chat_history} / {context} / {question}
    """
    rag_chain = (
        {"context": lambda x: get_retriever(), "question": lambda x: x["question"], "chat_history": lambda x: x["chat_history"]}
        | ChatPromptTemplate.from_template(template_answer) | llm | StrOutputParser()
    )

    # (2) ì‹œí—˜ ë¬¸ì œ ìƒì„± ì²´ì¸ (ì‹¤ì „ ì‹œí—˜ ëª¨ë“œìš©)
    # ì—­í• : ìš”ì²­ë°›ì€ ê°œìˆ˜ë§Œí¼ì˜ ë¬¸ì œë¥¼ JSONìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    template_exam = """
    [ì—­í• ] ë‹¹ì‹ ì€ ì—„ê²©í•œ ì‹œí—˜ ì¶œì œìœ„ì›ì…ë‹ˆë‹¤.
    [ì§€ì‹œ]
    ì œê³µëœ [ì»¨í…ìŠ¤íŠ¸] ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ **ì´ {num}ê°œì˜ ë‹¨ë‹µí˜• ë¬¸ì œ**ë¥¼ ì¶œì œí•˜ì„¸ìš”.
    ë°˜ë“œì‹œ ì•„ë˜ì˜ **JSON í˜•ì‹ìœ¼ë¡œë§Œ** ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ë§ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”.

    [JSON í˜•ì‹ ì˜ˆì‹œ]
    [
        {{"id": 1, "question": "ì§ˆë¬¸ ë‚´ìš©...", "answer": "ì •ë‹µ"}},
        {{"id": 2, "question": "ì§ˆë¬¸ ë‚´ìš©...", "answer": "ì •ë‹µ"}}
    ]

    [ìš”ì²­ ì‚¬í•­]
    - ë¬¸ì œ ê°œìˆ˜: {num}ê°œ
    - ë‚œì´ë„: í•µì‹¬ ë‚´ìš©ì„ ë‹¤ë£¨ëŠ” ì¤‘ê¸‰ ë‚œì´ë„
    - ì •ë‹µ: ëª…í™•í•œ ë‹¨ì–´ ìœ„ì£¼

    [ì»¨í…ìŠ¤íŠ¸]: {context}
    [JSON ì¶œë ¥]:
    """
    exam_chain = (
        {"context": lambda x: get_retriever(), "num": lambda x: x["question"]} 
        | ChatPromptTemplate.from_template(template_exam) | llm | StrOutputParser()
    )

    # (3) ì•”ê¸° ì¹´ë“œ ìƒì„± ì²´ì¸ (ì•”ê¸° ì¹´ë“œ ëª¨ë“œìš©)
    # ì—­í• : 4ê°œì˜ ì•”ê¸° ì¹´ë“œë¥¼ JSONìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.
    template_flashcard = """
    [ì—­í• ] í•™ìŠµ ë„êµ¬ ì œì‘ì
    [ì§€ì‹œ] í•µì‹¬ ë‚´ìš© ë³µìŠµìš© ì•”ê¸° ì¹´ë“œ 4ê°œë¥¼ ìƒì„±í•˜ì—¬ ì˜¤ì§ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.
    [JSON í˜•ì‹] [ {{"front": "...", "back": "..."}} ]
    [ì»¨í…ìŠ¤íŠ¸]: {context}
    """
    flashcard_chain = (
        {"context": lambda x: get_retriever(), "question": lambda x: x["question"]}
        | ChatPromptTemplate.from_template(template_flashcard) | llm | StrOutputParser()
    )

    print("âœ… Tutor Service: ëŒ€í™”/ì‹œí—˜/ì•”ê¸°ì¹´ë“œ ì²´ì¸ êµ¬ì„± ì„±ê³µ.")

except Exception as e:
    print(f"ğŸš¨ Tutor Service ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    rag_chain = None; exam_chain = None; flashcard_chain = None


# --- ë©”ì¸ ë¼ìš°í„° ---
def get_rag_response(question: str, chat_history: List[Dict[str, Any]], mode: str = 'chat') -> str:
    if rag_chain is None: return "ì˜¤ë¥˜: ì´ˆê¸°í™” ì‹¤íŒ¨"
    if get_retriever() is None: return "ì˜¤ë¥˜: PDF ì—†ìŒ"

    try:
        # 1. ì•”ê¸° ì¹´ë“œ ëª¨ë“œ
        if mode == 'flashcard':
            print("-> (F) ì•”ê¸° ì¹´ë“œ ìƒì„±")
            result = flashcard_chain.invoke({"question": question})
            return result.replace("```json", "").replace("```", "").strip()

        # 2. ì‹œí—˜ ìƒì„± ëª¨ë“œ (Exam Generation)
        if mode == 'exam':
            print(f"-> (E) ì‹œí—˜ ë¬¸ì œ {question}ê°œ ìƒì„± ì¤‘...")
            result = exam_chain.invoke({"question": question})
            return result.replace("```json", "").replace("```", "").strip()

        # 3. ëŒ€í™” ëª¨ë“œ (ê¸°ë³¸ê°’)
        print("-> (C) ì¼ë°˜ ë‹µë³€ (ëŒ€í™”ëª¨ë“œ)")
        formatted_history = "\n".join([f"{msg['role']}: {msg['content']}" for msg in chat_history])
        return rag_chain.invoke({"question": question, "chat_history": formatted_history})
        
    except Exception as e:
        print(f"ğŸš¨ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return f"ì˜¤ë¥˜ ë°œìƒ: {e}"